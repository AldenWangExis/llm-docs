---
title: LLM工程实践教程
index: false
---


## 当我们谈AI时，我们到底在谈什么

停车场的车牌识别系统已运转了二十年，抖音的推荐算法每天精准地预测你会刷哪条视频。这些AI像流水线工人：拧螺丝（数字识别、下棋）很专业，但换个任务就死机。2022年ChatGPT横空出世，同一个模型既能写代码又能讲笑话，从"单才"到"通才"的跨越，让开发者第一次觉得这东西有"脑子"。五年前的人们看到当今任何一个AI模型，都会发自内心绝对这就是“人工智能”。

从交互形式看，写Prompt确实很像在许愿：对着神像输入诉求（"给我一个比Manus更强的Agent项目"），模型always waiting，接收到输入后才输出结果。这种"吟唱咒语"式的调用方式，本质是在用自然语言描述你的需求边界，让概率分布在约束下收敛到可用的输出空间。咒语写得越精确，神像回应的准确率越高。

**然而AI不是许愿机**，只是在海量数据训练后学会"猜下一个词"的猴子打字机。

对开发者来说，这反而是好消息。提示词工程、API调用、RAG架构，这些操作比搭建Kubernetes集群要直观得多。问题从"如何训练AI"变成了"如何使用AI能力完成任务"，从底层算法退回到了我们熟悉的工程领域：数据流转、异常处理、成本优化。

下面的内容会先拆解几个核心概念（把LLM和数据库类比），再看看LLM工程里有哪些可选项，然后直接上手搭第一个应用。进阶部分按需阅读，不必强求线性消化。

## 内容结构

- **[第一部分：概念认知](01-concepts/)** - 用已知理解未知
- **[第二部分：LLM工程](02-models/)** - 知道用什么
- **[第三部分：工具链](03-tools/)** - 快速上手
- **[第四部分：进阶能力](04-advanced/)** - 从使用到精通
- **[附录](appendix/)** - 术语表、资源导航、常见问题

## 学习路径

**必读**：概念 → 模型 → 工具  
**按需**：进阶能力根据深入程度选择

## 前置要求

- 编程能力（Python优先）
- 系统架构思维
- 技术资源访问能力
