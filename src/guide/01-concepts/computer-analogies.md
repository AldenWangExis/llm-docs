# 用计算机架构理解 LLM

作为开发者，理解 LLM 最快的路径不是去学新概念，而是映射到已知的架构模式。如果暂时忽略那些新术语，把 LLM 应用当作一台计算机来看，会发现它的组件与传统计算机架构有着清晰的对应关系。

## 组件映射

### CPU = 模型本身

传统 CPU 执行指令、运算逻辑、输出结果。LLM 中的"模型"扮演了同样的角色：接收指令，处理输入，生成输出。

区别在于，这颗"CPU"在训练阶段就将海量知识压缩进了参数权重。它不仅有计算逻辑，还内置了数据。

### RAM = Context（上下文）

传统内存存放当前运行的程序和临时数据，断电即失。LLM 中的 Context 扮演相同角色：

- 存储当前会话的输入输出
- 存放为完成任务临时加载的参考资料
- 容量有限（token 限制）
- 会话结束后信息消失

### Storage = 外部数据库

当数据量超过 Context 容量限制时，需要外部存储。系统需要实现一套检索机制，在需要时从数据库中查询相关信息，加载到 Context 中供模型处理。

这就是 RAG（Retrieval-Augmented Generation）的核心逻辑：从硬盘换入内存。

### Kernel = 编排层

模型是硬件，编排代码就是操作系统。它负责：

- 调度模型调用
- 管理 Context 空间
- 决定何时检索外部数据
- 协调工具调用

## 核心差异

虽然架构对应清晰，但底层机制存在根本差异。忽视这些差异会带来工程风险。

### 从确定性到概率性

传统 CPU 基于确定性逻辑，`1+1` 永远等于 `2`。相同输入保证相同输出，结果不一致就是 Bug。

LLM 本质上是概率预测系统。它不做精确计算，而是在做"合理猜测"。这导致：

- 相同输入可能产生不同输出
- 不会因逻辑错误崩溃，而是静默输出错误结果
- "胡言乱语"是创造性的副产品，不是系统故障

这种**静默失败**特性要求开发者重新思考调试和监控策略。

### 指令集的质变

传统编程使用精确的语言（汇编、高级语言），编译器会检查语法错误。

LLM 使用自然语言作为"指令集"。这相当于用中文编写代码，但没有编译器。开发者需要像写法律条文一样设计提示词：既表达意图，又封堵歧义。

---

总结：这是一台"不完美的计算机"。内存昂贵且易失，CPU 聪明但会犯错，编程语言模糊且充满歧义。

理解这台计算机的脾气，就跨过了 LLM 工程的第一道门槛。

## 下一步

建立了架构映射后，是时候深入这颗"CPU"的内部机制了。它如何将文本转化为向量？为什么相同输入会产生不同输出？Temperature 参数背后的数学含义是什么？

[下一篇：LLM - 概率推理引擎](./llm.md) 将拆解这个黑盒，用工程师的语言解释其工作原理和接口规范。
