import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,f as p,a as r,d as i,b as t,w as s,r as l,o as c}from"./app-Cp5jA_bi.js";const d={};function h(m,e){const a=l("RouteLink");return c(),n("div",null,[e[2]||(e[2]=p('<h1 id="用计算机架构理解-llm" tabindex="-1"><a class="header-anchor" href="#用计算机架构理解-llm"><span>用计算机架构理解 LLM</span></a></h1><p>作为开发者，理解 LLM 最快的路径不是去学新概念，而是映射到已知的架构模式。如果暂时忽略那些新术语，把 LLM 应用当作一台计算机来看，会发现它的组件与传统计算机架构有着清晰的对应关系。</p><h2 id="组件映射" tabindex="-1"><a class="header-anchor" href="#组件映射"><span>组件映射</span></a></h2><h3 id="cpu-模型本身" tabindex="-1"><a class="header-anchor" href="#cpu-模型本身"><span>CPU = 模型本身</span></a></h3><p>传统 CPU 执行指令、运算逻辑、输出结果。LLM 中的&quot;模型&quot;扮演了同样的角色：接收指令，处理输入，生成输出。</p><p>区别在于，这颗&quot;CPU&quot;在训练阶段就将海量知识压缩进了参数权重。它不仅有计算逻辑，还内置了数据。</p><h3 id="ram-context-上下文" tabindex="-1"><a class="header-anchor" href="#ram-context-上下文"><span>RAM = Context（上下文）</span></a></h3><p>传统内存存放当前运行的程序和临时数据，断电即失。LLM 中的 Context 扮演相同角色：</p><ul><li>存储当前会话的输入输出</li><li>存放为完成任务临时加载的参考资料</li><li>容量有限（token 限制）</li><li>会话结束后信息消失</li></ul><h3 id="storage-外部数据库" tabindex="-1"><a class="header-anchor" href="#storage-外部数据库"><span>Storage = 外部数据库</span></a></h3><p>当数据量超过 Context 容量限制时，需要外部存储。系统需要实现一套检索机制，在需要时从数据库中查询相关信息，加载到 Context 中供模型处理。</p><p>这就是 RAG（Retrieval-Augmented Generation）的核心逻辑：从硬盘换入内存。</p><h3 id="kernel-编排层" tabindex="-1"><a class="header-anchor" href="#kernel-编排层"><span>Kernel = 编排层</span></a></h3><p>模型是硬件，编排代码就是操作系统。它负责：</p><ul><li>调度模型调用</li><li>管理 Context 空间</li><li>决定何时检索外部数据</li><li>协调工具调用</li></ul><h2 id="核心差异" tabindex="-1"><a class="header-anchor" href="#核心差异"><span>核心差异</span></a></h2><p>虽然架构对应清晰，但底层机制存在根本差异。忽视这些差异会带来工程风险。</p><h3 id="从确定性到概率性" tabindex="-1"><a class="header-anchor" href="#从确定性到概率性"><span>从确定性到概率性</span></a></h3><p>传统 CPU 基于确定性逻辑，<code>1+1</code> 永远等于 <code>2</code>。相同输入保证相同输出，结果不一致就是 Bug。</p><p>LLM 本质上是概率预测系统。它不做精确计算，而是在做&quot;合理猜测&quot;。这导致：</p><ul><li>相同输入可能产生不同输出</li><li>不会因逻辑错误崩溃，而是静默输出错误结果</li><li>&quot;胡言乱语&quot;是创造性的副产品，不是系统故障</li></ul><p>这种<strong>静默失败</strong>特性要求开发者重新思考调试和监控策略。</p><h3 id="指令集的质变" tabindex="-1"><a class="header-anchor" href="#指令集的质变"><span>指令集的质变</span></a></h3><p>传统编程使用精确的语言（汇编、高级语言），编译器会检查语法错误。</p><p>LLM 使用自然语言作为&quot;指令集&quot;。这相当于用中文编写代码，但没有编译器。开发者需要像写法律条文一样设计提示词：既表达意图，又封堵歧义。</p><hr><p>总结：这是一台&quot;不完美的计算机&quot;。内存昂贵且易失，CPU 聪明但会犯错，编程语言模糊且充满歧义。</p><p>理解这台计算机的脾气，就跨过了 LLM 工程的第一道门槛。</p><h2 id="下一步" tabindex="-1"><a class="header-anchor" href="#下一步"><span>下一步</span></a></h2><p>建立了架构映射后，是时候深入这颗&quot;CPU&quot;的内部机制了。它如何将文本转化为向量？为什么相同输入会产生不同输出？Temperature 参数背后的数学含义是什么？</p>',30)),r("p",null,[i(a,{to:"/guide/01-concepts/llm.html"},{default:s(()=>[...e[0]||(e[0]=[t("下一篇：LLM - 概率推理引擎",-1)])]),_:1}),e[1]||(e[1]=t(" 将拆解这个黑盒，用工程师的语言解释其工作原理和接口规范。",-1))])])}const g=o(d,[["render",h]]),x=JSON.parse('{"path":"/guide/01-concepts/computer-analogies.html","title":"用计算机架构理解 LLM","lang":"zh-CN","frontmatter":{"description":"用计算机架构理解 LLM 作为开发者，理解 LLM 最快的路径不是去学新概念，而是映射到已知的架构模式。如果暂时忽略那些新术语，把 LLM 应用当作一台计算机来看，会发现它的组件与传统计算机架构有着清晰的对应关系。 组件映射 CPU = 模型本身 传统 CPU 执行指令、运算逻辑、输出结果。LLM 中的\\"模型\\"扮演了同样的角色：接收指令，处理输入，生成...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"用计算机架构理解 LLM\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-09T11:55:02.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Alden\\",\\"url\\":\\"https://aldenwangexis.github.io/\\"}]}"],["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/llm-docs/guide/01-concepts/computer-analogies.html"}],["meta",{"property":"og:site_name","content":"LLM工程实践教程"}],["meta",{"property":"og:title","content":"用计算机架构理解 LLM"}],["meta",{"property":"og:description","content":"用计算机架构理解 LLM 作为开发者，理解 LLM 最快的路径不是去学新概念，而是映射到已知的架构模式。如果暂时忽略那些新术语，把 LLM 应用当作一台计算机来看，会发现它的组件与传统计算机架构有着清晰的对应关系。 组件映射 CPU = 模型本身 传统 CPU 执行指令、运算逻辑、输出结果。LLM 中的\\"模型\\"扮演了同样的角色：接收指令，处理输入，生成..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-09T11:55:02.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-09T11:55:02.000Z"}]]},"git":{"createdTime":1767862302000,"updatedTime":1767959702000,"contributors":[{"name":"AldenWangExis","username":"AldenWangExis","email":"wangzihao286@126.com","commits":3,"url":"https://github.com/AldenWangExis"}]},"readingTime":{"minutes":2.73,"words":819},"filePathRelative":"guide/01-concepts/computer-analogies.md","autoDesc":true}');export{g as comp,x as data};
